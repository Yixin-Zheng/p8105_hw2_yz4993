---
title: "p8105_hw2_yz4993"
author: "Yixin Zheng"
date: "2024-10-02"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

# Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r 1.1 data import and cleaning}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations. .

```{r 1.2 distinct stations number}
trans_ent |> 
  select(station_name, line) |> 
  distinct()
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r 1.3 ada compliant station number}
trans_ent |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r 1.4 proportion of station w/o v.a.e}
trans_ent |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r 1.5 distinct station A train + ada}
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()

trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

# Problem 2

```{r 2.1 data import and cleaning/ mr. trash wheel}
mr_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",      # specify the correct sheet
    skip = 1,                       # skip first rows (image)
    .name_repair = "minimal"        # suppress new names message
  ) |> 
  janitor::clean_names() |>         # clean column names to snake_case
  select(1:14) |>                   # select only the first 14 columns
  filter(!is.na(dumpster)) |>       # omit rows without dumpster-specific data
  mutate(
    year = as.double(year),                          # change variable type to num
    sports_balls = as.integer(round(sports_balls)),  # round and change to integer
    wheel_name = "mr.trash wheel"                    # add a variable for wheel
  )
```

```{r 2.2 data import and cleaning/ prof trash wheel}
prof_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",     # specify the correct sheet
    skip = 1,                       # skip first rows (image)
    .name_repair = "minimal"        # suppress new names message
  ) |> 
  janitor::clean_names() |>         # clean column names to snake_case
  select(1:13) |>                   # select only the first 13 columns
  filter(!is.na(dumpster)) |>       # omit rows without dumpster-specific data
  mutate(
    sports_balls = NA_integer_,     # add missing sports_balls column (integer)
    wheel_name = "professor trash wheel"             # add a variable for wheel
  )
```

```{r 2.3 data import and cleaning/ gwynnda trash wheel}
gwyn_trash_wheel = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",     # specify the correct sheet
    skip = 1,                       # skip first rows (image)
    .name_repair = "minimal"        # suppress new names message
  ) |> 
  janitor::clean_names() |>         # clean column names to snake_case
  select(1:12) |>                   # select only the first 12 columns
  filter(!is.na(dumpster)) |>       # omit rows without dumpster-specific data
  mutate(
    sports_balls = NA_integer_,    # add missing sports_balls column (integer)
    glass_bottles = NA_real_,        # add missing glass_bottles column (number)
    wheel_name = "gwynnda trash wheel"               # add a variable for wheel
  )
```

```{r 2.4 combine datasets}
trash_wheel = bind_rows(mr_trash_wheel, prof_trash_wheel, gwyn_trash_wheel)
names(trash_wheel)
```
The combined trash_wheel dataset contains a total of `r nrow(trash_wheel)` observations and `r ncol(trash_wheel)` variables, which are: `r paste(names(trash_wheel), collapse = ", ")`.

During data cleaning, for the `mr_trash_wheel` data sheet, we converted the variable type of `r colnames(trash_wheel)[3]` from character to numeric to ensure the dataset could be combined. Additionally, the `r colnames(trash_wheel)[13]` variable was rounded and converted to an integer as per the instructions.

Both the `prof_trash_wheel` and `gwyn_trash_wheel` datasets were missing the `r colnames(trash_wheel)[13]` column, and the `gwyn_trash_wheel` dataset was also missing the `r colnames(trash_wheel)[10]` column. To maintain consistency in the format of the dataset, these missing columns were added with NA values, enabling the use of the `bind_rows()` function for combining the datasets.

We also added a new variable, `wheel_name`, to each dataset to identify the specific trash wheel. Key variables include `r colnames(trash_wheel)[5]`, which indicates the weight of trash collected (in tons), and `r colnames(trash_wheel)[6]`, which measures the volume of trash collected (in cubic yards) for each corresponding dumpster. The variables `r paste(colnames(trash_wheel)[7:13], collapse = ", ")` represent different types of trash collected, such as plastic bottles and cigarette butts. Finally, the variable `r colnames(trash_wheel)[14]` denotes the number of homes powered by the electricity generated from the collected trash, where each ton of trash equates to an average of 500 kilowatts of electricity, and an average household uses approximately 30 kilowatts per day.

```{r 2.5 calculate}
# total weight of trash collected by Professor Trash Wheel
prof_total_weight <- trash_wheel %>%
  filter(wheel_name == "professor trash wheel") %>%
  pull(weight_tons) %>%
  sum(na.rm = TRUE)

# total number of cigarette butts collected by Gwynnda in June of 2022
gwyn_2022_6_cigarette_butts <- trash_wheel %>%
  filter(wheel_name == "gwynnda trash wheel", month == "June", year == 2022) %>%
  pull(cigarette_butts) %>%
  sum(na.rm = TRUE)

prof_total_weight
gwyn_2022_6_cigarette_butts
```

As the code result shown, the total weight of trash collected by Professor Trash Wheel is 246.74 tons, and the total number of cigarette butts collected by Gwynnda in June of 2022 is 18120.


# Problem 3
```{r 3.1 data import and cleaning and wrangling}
bakers = 
  read_csv(
    "data/gbb_datasets/bakers.csv"    # specify the correct path
  ) |> 
  janitor::clean_names() |>           # clean column names to snake_case
  filter(!is.na(baker_name)) |>       # filter "baker_name" column to omit NA
  separate(
    baker_name, 
    into = c("first_name", "last_name"), 
    sep = " ", 
    extra = "merge")                  # split first and last names

bakes = 
  read_csv(
    "data/gbb_datasets/bakes.csv",    # specify the correct path
  ) |> 
  janitor::clean_names() |>            # clean column names to snake_case
  filter(!is.na(baker))                # filter "baker" column to omit NA

results = 
  read_csv(
    "data/gbb_datasets/results.csv",    # specify the correct path
    skip = 2) |>                        # skip the first 2 rows (notes)
  janitor::clean_names() |>             # clean column names to snake_case
  filter(!is.na(baker))                 # filter rows "baker" column to omit NA
```


```{r 3.2 completeness and correctness}
# checking for missing values
sum(is.na(bakers))
sum(is.na(bakes))
sum(is.na(results))

colnames(bakers)
colnames(bakes)
colnames(results)

# check for bakers in bakes.csv that do not exist in bakers.csv based on first name
anti_join(bakes, bakers, by = c("baker" = "first_name"))

# check for bakers in bakes.csv that do not exist in results.csv
anti_join(bakes, results, by = c("baker" = "baker"))

# check for bakers in bakers.csv that do not exist in results.csv based on first name
anti_join(bakers, results, by = c("first_name" = "baker"))

```

